{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# verigy whether nonflat/distort boundary models are easier to be adversarial attack\n",
    "# time or distortion\n",
    "# here we choose time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fgsm attack\n",
    "# import modules\n",
    "from deepvisualinsight.MMS import MMS\n",
    "from deepvisualinsight import utils\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "content_path = \"E:\\\\DVI_exp_data\\\\active_learning\\\\LeastConfidence\"\n",
    "sys.path.append(content_path)\n",
    "\n",
    "from Model.model import *\n",
    "net = ResNet18()\n",
    "classes = (\"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "mms = MMS(content_path, net, 1, 20, 1, 512, 10, classes, cmap=\"tab10\", resolution=100, neurons=256,\n",
    "          verbose=1, temporal=False, split=-1, advance_border_gen=True, attack_device=\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "EPOCH=10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_location = os.path.join(mms.model_path, \"Epoch_{:d}\".format(EPOCH), \"subject_model.pth\")\n",
    "mms.model.load_state_dict(torch.load(model_location, map_location=torch.device(\"cpu\")))\n",
    "mms.model = mms.model.to(mms.device)\n",
    "mms.model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "epsilons = [.01,.03,.05,.1]\n",
    "epsilon = .01\n",
    "\n",
    "def adv_attack(image, epsilon, data_grad):\n",
    "\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = torch.sign(data_grad)\n",
    "\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "    return perturbed_image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fgsm: how many adv samples we can get\n",
    "# ifgsm: set a time limit\n",
    "TEST_BUDGET = 1000\n",
    "\n",
    "CIFAR_NORM = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(*CIFAR_NORM)])\n",
    "testset = torchvision.datasets.CIFAR10(root='data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_subset = torch.utils.data.Subset(testset, np.arange(TEST_BUDGET))\n",
    "testloader = torch.utils.data.DataLoader(test_subset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"attack with epsilon {}...\".format(epsilon))\n",
    "\n",
    "succ = 0\n",
    "for i, (data, target) in enumerate(testloader, 0):\n",
    "    # Send the data and label to the device\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    # Set requires_grad attribute of tensor. Important for Attack\n",
    "    data.requires_grad = True\n",
    "    # Forward pass the data through the model\n",
    "    output = mms.model(data)\n",
    "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "    # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "    if init_pred.item() != target.item():\n",
    "        continue\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = torch.nn.functional.nll_loss(output, target)\n",
    "\n",
    "    # Zero all existing gradients\n",
    "    mms.model.zero_grad()\n",
    "\n",
    "    # Calculate gradients of model in backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Collect datagrad\n",
    "    data_grad = data.grad.data\n",
    "\n",
    "    # Call FGSM Attack\n",
    "    perturbed_data = adv_attack(data, epsilon, data_grad)\n",
    "\n",
    "    # Re-classify the perturbed image\n",
    "    output = mms.model(perturbed_data)\n",
    "\n",
    "    # Check for success\n",
    "    final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    if final_pred.item() != target.item():\n",
    "        succ += 1\n",
    "succ"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}