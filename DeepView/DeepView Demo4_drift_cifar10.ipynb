{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepview import DeepView\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "# ---------------------------\n",
    "import demo_utils as demo\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib qt seems to be a bit buggy with notebooks, so we execute it multiple times\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device will be detected automatically\n",
    "# Set to 'cpu' or 'cuda:0' to set the device manually\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "testset = demo.make_cifar_dataset()\n",
    "torch_model = demo.create_torch_model(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax operation to use in pred_wrapper\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "# this is the prediction wrapper, it encapsulates the call to the model\n",
    "# and does all the casting to the appropriate datatypes\n",
    "def pred_wrapper(x):\n",
    "    with torch.no_grad():\n",
    "        x = np.array(x, dtype=np.float32)\n",
    "        tensor = torch.from_numpy(x).to(device)\n",
    "        logits = torch_model(tensor)\n",
    "        probabilities = softmax(logits).cpu().numpy()\n",
    "    return probabilities\n",
    "\n",
    "def visualization(image, point2d, pred, label=None, title=None):\n",
    "    f, a = plt.subplots()\n",
    "    a.set_title(title)\n",
    "    a.imshow(image.transpose([1, 2, 0]))\n",
    "\n",
    "# the classes in the dataset to be used as labels in the plots\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# --- Deep View Parameters ----\n",
    "batch_size = 512\n",
    "max_samples = 1000\n",
    "data_shape = (3, 32, 32)\n",
    "n = 5\n",
    "lam = .65\n",
    "resolution = 100\n",
    "cmap = 'tab10'\n",
    "title = 'ResNet-20 - CIFAR10'\n",
    "\n",
    "deepview = DeepView(pred_wrapper, classes, max_samples, batch_size, \n",
    "                    data_shape, n, lam, resolution, cmap, title=title, data_viz=visualization)\n",
    "\n",
    "umapParms = {\n",
    "    \"random_state\": 42*42,\n",
    "    \"n_neighbors\": 30,\n",
    "    \"spread\": 1,\n",
    "    \"min_dist\": 0.1,\n",
    "    \"a\": 600\n",
    "}\n",
    "#\"verbose\": True,\n",
    "deepview._init_mappers(None, None, umapParms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select random points and visualize them together with the classifier\n",
    "n_samples = 300\n",
    "sample_ids = np.random.choice(len(testset), n_samples)\n",
    "X = np.array([ testset[i][0].numpy() for i in sample_ids ])\n",
    "Y = np.array([ testset[i][1] for i in sample_ids ])\n",
    "\n",
    "t0 = time.time()\n",
    "deepview.add_samples(X, Y)\n",
    "deepview.show()\n",
    "\n",
    "\n",
    "print('Time to calculate visualization for %d samples: %.2f sec' % (n_samples, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose additional points from one class and add these to deepView\n",
    "n_samples = 50\n",
    "# go through the data set and select the first data points with label pick_l\n",
    "pick_l = 0\n",
    "i = 0\n",
    "count = 0\n",
    "X = np.empty([n_samples, data_shape[0], data_shape[1], data_shape[2]])\n",
    "Y = np.empty([n_samples])\n",
    "while (count < n_samples):\n",
    "    if testset[i][1] == 0:\n",
    "        #print(i)\n",
    "        X[count,:,:,:] = testset[i][0] #*0.2 # simulate darker\n",
    "        X[count,0,:,:] = X[count,0,:,:] + 6 # simulate sunset\n",
    "        Y[count] = testset[i][1]\n",
    "        count += 1\n",
    "    i += 1\n",
    "\n",
    "t0 = time.time()\n",
    "deepview.resolution = 200\n",
    "deepview.add_samples(X, Y)\n",
    "deepview.show()\n",
    "\n",
    "\n",
    "print('Time to calculate visualization for %d samples: %.2f sec' % (n_samples, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepview.resolution = 200\n",
    "deepview.update_mappings()\n",
    "deepview.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X.max()\n",
    "\n",
    "f, a = plt.subplots()\n",
    "#curr_img = testset[10][0].numpy().transpose([1, 2, 0])\n",
    "curr_img = X[1].copy().transpose([1, 2, 0])\n",
    "print(curr_img.shape)\n",
    "curr_img[:,:,0] = curr_img[:,:,0]\n",
    "curr_img = curr_img - curr_img.min()\n",
    "curr_img = curr_img/curr_img.max()\n",
    "a.imshow(curr_img)#, vmin = curr_img.min()*1.2,vmax=curr_img.max()*1.2)#, vmin=-2.1, vmax=2.6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
