{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepview import DeepView\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "# ---------------------------\n",
    "import demo_utils as demo\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib qt seems to be a bit buggy with notebooks, so we execute it multiple times\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# device will be detected automatically\n",
    "# Set to 'cpu' or 'cuda:0' to set the device manually\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "testset = demo.make_cifar_dataset()\n",
    "torch_model = demo.create_torch_model(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "def pred_wrapper(x):\n",
    "    with torch.no_grad():\n",
    "        x = np.array(x, dtype=np.float32)\n",
    "        tensor = torch.from_numpy(x).to(device)\n",
    "        logits = torch_model(tensor)\n",
    "        probabilities = softmax(logits).cpu().numpy()\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# --- Deep View Parameters ----\n",
    "batch_size = 128\n",
    "max_samples = 1000\n",
    "data_shape = (3, 32, 32)\n",
    "n = 5\n",
    "lam = .65\n",
    "resolution = 100\n",
    "cmap = 'tab10'\n",
    "title = 'ResNet-20 - CIFAR10'\n",
    "\n",
    "\n",
    "deepview = DeepView(pred_wrapper, classes, max_samples, batch_size, \n",
    "                    data_shape, n, lam, resolution, cmap, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "n_samples = 300\n",
    "# later special points will be added\n",
    "add_points = 1\n",
    "\n",
    "np.random.seed(42)\n",
    "#sample_ids = np.random.choice(len(testset), n_samples)\n",
    "sample_ids = np.random.permutation(len(testset))[0:n_samples+add_points]\n",
    "print(sample_ids[0:5])\n",
    "\n",
    "X = np.array([ testset[i][0].numpy() for i in sample_ids ])\n",
    "Y = np.array([ testset[i][1] for i in sample_ids ])\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_fisher_matrix_comps import compute_fisher_matrix_comps\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib as plotlib\n",
    "import torch.nn.functional as F\n",
    "\n",
    "mean_ = [0.485, 0.456, 0.406]\n",
    "std_  = [0.229, 0.224, 0.225]\n",
    "# range of the data\n",
    "minV = (0 - mean_[0])/std_[0]\n",
    "maxV = (1 - mean_[0])/std_[0]\n",
    "\n",
    "# create an adversarial example and include it into the data set\n",
    "data      = testset.__getitem__(1) # 1, 7\n",
    "data_item = torch.zeros([1, data_shape[0], data_shape[1], data_shape[2]]).to(device)\n",
    "data_item[0,:,:,:] = data[0]\n",
    "labs_curr = data[1]\n",
    "\n",
    "print(\"curr label\", labs_curr)\n",
    "\n",
    "n_data = n_samples\n",
    "p_cgivenx = torch.zeros([1, len(classes)]).to(device)\n",
    "used_values = -1 * torch.ones([1, len(classes)+1], dtype=torch.long);\n",
    "used_values[:, -1] = len(classes) \n",
    "\n",
    "\n",
    "data_item.requires_grad = True\n",
    "output                  = torch_model(data_item)\n",
    "p_cgivenx[-1,:]         = softmax(output.detach())\n",
    "# compute derivative wrt the input\n",
    "loss = F.cross_entropy(output, torch.tensor([labs_curr]).to(device))\n",
    "torch_model.zero_grad()\n",
    "loss.backward(retain_graph=True)\n",
    "data_grad = data_item.grad.data\n",
    "\n",
    "\n",
    "# print true label, predicted label and certainty\n",
    "print(\"all predictions \", p_cgivenx) \n",
    "print(\"True Lab / cert:\", classes[labs_curr], \"/\", p_cgivenx[-1,labs_curr].item()) \n",
    "val,idx = torch.max(p_cgivenx, 1)\n",
    "print(\"Pred Lab / cert:\", classes[idx.item()], \"/\", p_cgivenx[-1,idx.item()].item()) \n",
    "\n",
    "# plot the adversarial example\n",
    "fig, axes = plt.subplots(1,4, figsize=(8, 6))\n",
    "image = (data_item[0,:,:,:].detach() * std_[0] + mean_[0]).cpu().numpy().transpose([1, 2, 0])\n",
    "axes[0].imshow(image)\n",
    "image = (data_grad[-1].detach() * std_[0] + mean_[0]).cpu().numpy().transpose([1, 2, 0])\n",
    "axes[1].imshow(image)\n",
    "image = (data_grad[-1].sign().detach() * std_[0] + mean_[0]).cpu().numpy().transpose([1, 2, 0])\n",
    "axes[2].imshow(image)\n",
    "axes[0].axis('off'), axes[1].axis('off'), axes[2].axis('off'), axes[3].axis('off')\n",
    "#plt.show()\n",
    "\n",
    "# perform the pertubation\n",
    "perturbed_dat = data_item[0,:,:,:] + 0.1*(data_grad[-1].sign())\n",
    "perturbed_dat = torch.clamp(perturbed_dat, minV, maxV)\n",
    "# check the classification\n",
    "tmp                 = torch.zeros([1, data_shape[0], data_shape[1], data_shape[2]]).to(device)\n",
    "tmp[:,:,:,:]        = perturbed_dat\n",
    "output              = torch_model(tmp)\n",
    "p_cgivenx[-1,:]     = softmax(output.detach())\n",
    "\n",
    "image = (perturbed_dat.detach() * std_[0] + mean_[0]).cpu().numpy().transpose([1, 2, 0])\n",
    "axes[3].imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(\"all predictions adv\", p_cgivenx)\n",
    "val,idx = torch.sort(p_cgivenx[0], descending=True)\n",
    "print(\"indices after sorting\", idx)\n",
    "print(\"Top predictions are\", classes[idx[0].item()] + \", \" + \n",
    "      classes[idx[1].item()] + \", \" + classes[idx[2].item()])\n",
    "\n",
    "\n",
    "X[-1,:,:,:] = tmp.detach().cpu().numpy()\n",
    "Y[-1] = labs_curr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import deepview.embeddings as embeddings\n",
    "\n",
    "np.random.seed(42)\n",
    "rseed = round(np.random.rand() * 1e10)\n",
    "\n",
    "umapParms = {\n",
    "    \"random_state\": rseed,\n",
    "    \"n_neighbors\": 30,\n",
    "    \"spread\": 1,\n",
    "    \"min_dist\": 0.1,\n",
    "}\n",
    "#     \"verbose\": True\n",
    "deepview._init_mappers(None, None, umapParms)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "deepview.add_samples(X, Y)\n",
    "\n",
    "\n",
    "#deepview.resolution = 200\n",
    "#deepview.update_mappings()\n",
    "\n",
    "deepview.show()\n",
    "\n",
    "print('Time to calculate visualization for %d samples: %.2f sec' % (n_samples, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or in more pretty ...\n",
    "deepview.resolution = 200\n",
    "deepview.update_mappings()\n",
    "\n",
    "deepview.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect how far the adv example is away from the other points according to different metrics\n",
    "idx_plt = -1 # adv point\n",
    "\n",
    "#fish_dists_orig[-1, :] or eucl_dists or fish_dists\n",
    "n_classes = len(classes)\n",
    "msize_s = 8\n",
    "cmap = \"tab10\"\n",
    "cmap = plt.get_cmap(cmap)\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import floyd_warshall\n",
    "fish_dists_spaths = csr_matrix(deepview.distances) #discr_distances\n",
    "fish_dists_spaths = floyd_warshall(csgraph=fish_dists_spaths, directed=False, unweighted=False)\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(14, 8))\n",
    "for c in range(n_classes):\n",
    "    axes[0].plot(deepview.eucl_distances[idx_plt, Y==c], c*np.ones([sum(Y==c)]), \n",
    "                 'o', c=cmap(c/(n_classes-1)), label=classes[c], markersize=msize_s)\n",
    "    axes[1].plot(deepview.discr_distances[idx_plt, Y==c], c*np.ones([sum(Y==c)]), \n",
    "                 'o', c=cmap(c/(n_classes-1)), label=classes[c], markersize=msize_s)\n",
    "    axes[2].plot(deepview.distances[idx_plt, Y==c], c*np.ones([sum(Y==c)]), \n",
    "                 'o', c=cmap(c/(n_classes-1)), label=classes[c], markersize=msize_s)\n",
    "    axes[3].plot(fish_dists_spaths[idx_plt, Y==c], c*np.ones([sum(Y==c)]), \n",
    "                 'o', c=cmap(c/(n_classes-1)), label=classes[c], markersize=msize_s)\n",
    "    \n",
    "\n",
    "axes[0].set_title('euclidean dist from adv', fontsize=12)\n",
    "axes[1].set_title('fisher dist from adv', fontsize=12)\n",
    "axes[2].set_title('regul fisher dist from adv', fontsize=12)\n",
    "axes[3].set_title('shortest paths fisher dist', fontsize=12)\n",
    "\n",
    "#labs_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
