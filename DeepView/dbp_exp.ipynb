{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBP experiment\n",
    "1. run tp-tp model and tp-dbp model\n",
    "2. set k to a smaller number and verify my guess\n",
    "3. use edge dataset to evaluate the knn property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* parametric_umap, tp-tp -> encoder_original\n",
    "* parametric_umap_DBP,tp-tp -> encoder_core\n",
    "* parametric_umap_DBP, tp-dbp -> encoder_dbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\dbp_exp\\encoder_original\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_location = \"parametric_umap_models\\dbp_exp\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_original\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))\n",
    "\n",
    "# # load decoder\n",
    "# decoder_output = os.path.join(save_location, \"decoder_original\")\n",
    "# if os.path.exists(decoder_output):\n",
    "#     load_decoder = tf.keras.models.load_model(decoder_output)\n",
    "#     print(\"Keras decoder model loaded from {}\".format(decoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data = np.load(\"train_data.npy\")\n",
    "train_pred_labels = np.load(\"train_pred_labels.npy\")\n",
    "test_data = np.load(\"test_data.npy\")\n",
    "test_pred_labels = np.load(\"test_pred_labels.npy\")\n",
    "border_center = np.load(\"border_center.npy\")\n",
    "border_center_labels= np.load(\"border_center_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-7a447566bb7c>:1: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n"
     ]
    }
   ],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=N) \n",
    "_, low_ind = low_tree.query(low_train, k=N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32185,  9015,  2494,  1806,  3116,  1093,   162,    66,    49,\n",
       "          13,     1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(border_pres.astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\dbp_exp\\encoder_core\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_location = \"parametric_umap_models\\dbp_exp\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_core\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))\n",
    "\n",
    "# # load decoder\n",
    "# decoder_output = os.path.join(save_location, \"decoder_core\")\n",
    "# if os.path.exists(decoder_output):\n",
    "#     load_decoder = tf.keras.models.load_model(decoder_output)\n",
    "#     print(\"Keras decoder model loaded from {}\".format(decoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=N) \n",
    "_, low_ind = low_tree.query(low_train, k=N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22767, 10797,  6282,  5752,  2907,  1162,   306,    15,    12],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(border_pres.astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\dbp_exp\\encoder_dbp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_location = \"parametric_umap_models\\dbp_exp\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_dbp\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))\n",
    "\n",
    "# # load decoder\n",
    "# decoder_output = os.path.join(save_location, \"decoder_dbp\")\n",
    "# if os.path.exists(decoder_output):\n",
    "#     load_decoder = tf.keras.models.load_model(decoder_output)\n",
    "#     print(\"Keras decoder model loaded from {}\".format(decoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=N) \n",
    "_, low_ind = low_tree.query(low_train, k=N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33452,  9499,  5792,   465,   302,   184,   117,    94,    66,\n",
       "          28,     1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(border_pres.astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\dbp_exp\\encoder_withouttp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_location = \"parametric_umap_models\\dbp_exp\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_withouttp\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))\n",
    "\n",
    "# # load decoder\n",
    "# decoder_output = os.path.join(save_location, \"decoder_dbp\")\n",
    "# if os.path.exists(decoder_output):\n",
    "#     load_decoder = tf.keras.models.load_model(decoder_output)\n",
    "#     print(\"Keras decoder model loaded from {}\".format(decoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=N) \n",
    "_, low_ind = low_tree.query(low_train, k=N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42618,  6516,   237,   148,   140,   118,    89,    93,    39,\n",
       "           2], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(border_pres.astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42618"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(border_pres)-np.count_nonzero(border_pres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the edge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 2048)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_num = 50000\n",
    "augmentation_num = 10000\n",
    "border_num = 5000\n",
    "\n",
    "fitting_data = np.concatenate((train_data[-train_num:],\n",
    "#                                augmentation_data[:augmentation_num],\n",
    "                               border_center[:border_num]), axis=0)\n",
    "fitting_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of trees in random projection forest\n",
    "n_trees = 5 + int(round((fitting_data.shape[0]) ** 0.5 / 20.0))\n",
    "# max number of nearest neighbor iters to perform\n",
    "n_iters = max(5, int(round(np.log2(fitting_data.shape[0]))))\n",
    "# distance metric\n",
    "metric = \"euclidean\"\n",
    "# number of neighbors for computing k-neighbor graph\n",
    "n_neighbors = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 13 19:21:17 2021 Building RP forest with 17 trees\n",
      "Wed Jan 13 19:21:20 2021 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\tStopping threshold met -- exiting after 3 iterations\n"
     ]
    }
   ],
   "source": [
    "from pynndescent import NNDescent\n",
    "# get nearest neighbors\n",
    "nnd = NNDescent(\n",
    "    fitting_data.reshape((len(fitting_data), np.product(np.shape(fitting_data)[1:]))),\n",
    "    n_neighbors=n_neighbors,\n",
    "    metric=metric,\n",
    "    n_trees=n_trees,\n",
    "    n_iters=n_iters,\n",
    "    max_candidates=60,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "from umap.umap_ import fuzzy_simplicial_set\n",
    "knn_indices, knn_dists = nnd.neighbor_graph\n",
    "random_state = check_random_state(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_graph, sigmas, rhos, dists = fuzzy_simplicial_set(\n",
    "    X=fitting_data,\n",
    "    n_neighbors=n_neighbors,\n",
    "    metric=metric,\n",
    "    random_state=random_state,\n",
    "    knn_indices=knn_indices,\n",
    "    knn_dists=knn_dists,\n",
    "    return_dists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<55000x55000 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 1099766 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = umap_graph.tocoo()\n",
    "graph.sum_duplicates()\n",
    "graph.eliminate_zeros()\n",
    "graph.data[graph.data < (graph.data.max() / float(500))] = 0.0\n",
    "graph.eliminate_zeros()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099766, 1099766)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head,tail,weight= graph.row,graph.col,graph.data\n",
    "len(head),len(tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003620"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_head = (head<50000)\n",
    "tp_tail = (tail<50000)\n",
    "tp_tp = (tp_head & tp_tail)\n",
    "np.sum(tp_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85116"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbp_head = (head>=50000)\n",
    "dbp_tail = (tail>=50000)\n",
    "dbp_dbp = (dbp_head & dbp_tail)\n",
    "np.sum(dbp_dbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11030"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_dbp = ((tp_head & dbp_tail) | (dbp_head & tp_tail))\n",
    "np.sum(tp_dbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5515"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_dbp = (tp_head & dbp_tail)\n",
    "np.sum(tp_dbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1009135, 1009136, 1009137, ..., 1099649, 1099650, 1099666],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = np.argwhere(tp_dbp==True)\n",
    "edges = np.squeeze(edges)\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp-tp\n",
    "low_fitting_data = load_encoder(fitting_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.6621539374880987, 2.76190855788689)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = np.zeros(len(edges))\n",
    "for i in range(len(edges)):\n",
    "    h = low_fitting_data[head[edges[i]]]\n",
    "    t = low_fitting_data[tail[edges[i]]]\n",
    "    dists[i] = np.linalg.norm(h-t)\n",
    "dists.mean(), np.std(dists,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.881431530302024, 8.13159089576581)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = np.zeros(len(edges))\n",
    "for i in range(len(edges)):\n",
    "    h = low_fitting_data[head[edges[i]]]\n",
    "    t = low_fitting_data[tail[neg[i]]]\n",
    "    dists[i] = np.linalg.norm(h-t)\n",
    "dists.mean(), np.std(dists,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp-tp core\n",
    "low_fitting_data = load_encoder(fitting_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.240253884779291, 3.6968340137081337)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = np.zeros(len(edges))\n",
    "for i in range(len(edges)):\n",
    "    h = low_fitting_data[head[edges[i]]]\n",
    "    t = low_fitting_data[tail[edges[i]]]\n",
    "    dists[i] = np.linalg.norm(h-t)\n",
    "dists.mean(), np.std(dists,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.441977167531428, 10.332535596078399)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = np.zeros(len(edges))\n",
    "for i in range(len(edges)):\n",
    "    h = low_fitting_data[head[edges[i]]]\n",
    "    t = low_fitting_data[tail[neg[i]]]\n",
    "    dists[i] = np.linalg.norm(h-t)\n",
    "dists.mean(), np.std(dists,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp-dbp\n",
    "low_fitting_data = load_encoder(fitting_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6543270221647088, 0.41393987605949595)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = np.zeros(len(edges))\n",
    "for i in range(len(edges)):\n",
    "    h = low_fitting_data[head[edges[i]]]\n",
    "    t = low_fitting_data[tail[edges[i]]]\n",
    "    dists[i] = np.linalg.norm(h-t)\n",
    "dists.mean(), np.std(dists,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.838728493410867, 2.3704286107589785)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = np.zeros(len(edges))\n",
    "for i in range(len(edges)):\n",
    "    h = low_fitting_data[head[edges[i]]]\n",
    "    t = low_fitting_data[tail[neg[i]]]\n",
    "    dists[i] = np.linalg.norm(h-t)\n",
    "dists.mean(), np.std(dists,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp-dbp+dbp-dbp\n",
    "low_fitting_data = load_encoder(fitting_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5080731251336978, 0.5900279612300334)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = np.zeros(len(edges))\n",
    "for i in range(len(edges)):\n",
    "    h = low_fitting_data[head[edges[i]]]\n",
    "    t = low_fitting_data[tail[edges[i]]]\n",
    "    dists[i] = np.linalg.norm(h-t)\n",
    "dists.mean(), np.std(dists,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.379653172588765, 2.761048049037231)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = np.zeros(len(edges))\n",
    "for i in range(len(edges)):\n",
    "    h = low_fitting_data[head[edges[i]]]\n",
    "    t = low_fitting_data[tail[neg[i]]]\n",
    "    dists[i] = np.linalg.norm(h-t)\n",
    "dists.mean(), np.std(dists,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.379653172588765, 2.761048049037231)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = np.random.permutation(len(edges))\n",
    "neg = edges[neg]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python xianglinDR2",
   "language": "python",
   "name": "dr2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
