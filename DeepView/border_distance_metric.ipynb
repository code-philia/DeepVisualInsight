{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boudary preserverance \n",
    "1. find border points\n",
    "2. first calculate the DBP perserving for normal data augmentation\n",
    "3. then change parametric umap, again calculate DBP perserving for train_data+augmentation_data+DBP\n",
    "4. knn preserving evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from tensorboardX import SummaryWriter\n",
    "from cifar10_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 2048\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Model successfully...\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = resnet50(pretrained=True)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(\"Load Model successfully...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "data_shape = (2048,)\n",
    "\n",
    "ADD_NOISE = False\n",
    "n_hidden = 500\n",
    "dim_img = INPUT_SIZE  # number of pixels for a MNIST image\n",
    "dim_z = 2\n",
    "\n",
    "# train\n",
    "n_epochs = 500\n",
    "batch_size = 200\n",
    "learn_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50000, 3, 32, 32), (50000, 2048), (50000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR10 Test dataset and dataloader declaration\n",
    "CIFAR_NORM = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(*CIFAR_NORM)])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "training_data = np.zeros((50000, 3, 32, 32))\n",
    "\n",
    "for i, (data, target) in enumerate(trainloader, 0):\n",
    "    r1, r2 = i * 200, (i + 1) * 200\n",
    "    training_data[r1:r2] = data\n",
    "\n",
    "train_pred_labels = np.zeros(50000)\n",
    "raw_input_X = torch.from_numpy(training_data).to(device, dtype=torch.float)\n",
    "input_X = np.zeros([len(raw_input_X), data_shape[0]])\n",
    "output_Y = np.zeros(len(raw_input_X))\n",
    "n_batches = max(math.ceil(len(raw_input_X) / batch_size), 1)\n",
    "for b in range(n_batches):\n",
    "    r1, r2 = b * batch_size, (b + 1) * batch_size\n",
    "    inputs = raw_input_X[r1:r2]\n",
    "    with torch.no_grad():\n",
    "        pred = model.gap(inputs).cpu().numpy()\n",
    "         input_X[r1:r2] = pred\n",
    "        pred = model(inputs).cpu().numpy().argmax(axis=1)\n",
    "        output_Y[r1:r2] = pred\n",
    "train_data = input_X    # (50000,2048)\n",
    "train_pred_labels = output_Y\n",
    "\n",
    "training_data.shape, train_data.shape, train_pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 2048), (50000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.load(\"train_data.npy\")\n",
    "train_pred_labels = np.load(\"train_pred_labels.npy\")\n",
    "train_data.shape, train_pred_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000, 3, 32, 32), (10000, 2048), (10000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR10 Test dataset and dataloader declaration\n",
    "CIFAR_NORM = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(*CIFAR_NORM)])\n",
    "testset = torchvision.datasets.CIFAR10(root='data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=200,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testing_data = np.zeros((10000, 3, 32, 32))\n",
    "for i, (data, target) in enumerate(testloader, 0):\n",
    "    r1, r2 = i * 200, (i + 1) * 200\n",
    "    testing_data[r1:r2] = data\n",
    "\n",
    "raw_input_X = torch.from_numpy(testing_data).to(device, dtype=torch.float)\n",
    "input_X = np.zeros([len(raw_input_X), data_shape[0]])\n",
    "output_Y = np.zeros(len(raw_input_X))\n",
    "n_batches = max(math.ceil(len(raw_input_X) / batch_size), 1)\n",
    "for b in range(n_batches):\n",
    "    r1, r2 = b * batch_size, (b + 1) * batch_size\n",
    "    inputs = raw_input_X[r1:r2]\n",
    "    with torch.no_grad():\n",
    "        pred = model.gap(inputs).cpu().numpy()\n",
    "        input_X[r1:r2] = pred\n",
    "        pred = model(inputs).cpu().numpy().argmax(axis=1)\n",
    "        output_Y[r1:r2] = pred\n",
    "test_data = input_X    # (10000,2048)\n",
    "test_pred_labels = output_Y\n",
    "\n",
    "testing_data.shape, test_data.shape, test_pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2048), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.load(\"test_data.npy\")\n",
    "test_pred_labels = np.load(\"test_pred_labels.npy\")\n",
    "test_data.shape, test_pred_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### augmentation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "epsilons = [.01,.03,.05,.1]\n",
    "epsilon = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_attack(image, epsilon, data_grad):\n",
    "    \n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = torch.sign(data_grad)\n",
    "    \n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    " \n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack with epsilon 0.01...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 3, 32, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fgsm\n",
    "print(\"attack with epsilon {}...\".format(epsilon))\n",
    "\n",
    "adv_data = np.zeros((50000, 3, 32, 32))\n",
    "for i, (data, target) in enumerate(trainloader, 0):\n",
    "    r1, r2 = i * 200, (i + 1) * 200\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Set requires_grad attribute of tensor. Important for Attack\n",
    "    data.requires_grad = True\n",
    "\n",
    "    # Forward pass the data through the model\n",
    "    output = model(data)\n",
    "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "    loss = criterion(output, target) # loss for ground-truth class\n",
    "\n",
    "    # Back propogation\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Collect data_grad\n",
    "    data_grad = data.grad.data\n",
    "\n",
    "    # Call Attack\n",
    "    perturbed_data = adv_attack(data, epsilon, data_grad)\n",
    "\n",
    "    adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "    adv_data[r1:r2] = adv_ex\n",
    "\n",
    "adv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3, 32, 32), (50000, 2048))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input_X = torch.from_numpy(adv_data).to(device, dtype=torch.float)\n",
    "input_X = np.zeros([len(raw_input_X), data_shape[0]])\n",
    "n_batches = max(math.ceil(len(raw_input_X) / batch_size), 1)\n",
    "for b in range(n_batches):\n",
    "    r1, r2 = b * batch_size, (b + 1) * batch_size\n",
    "    inputs = raw_input_X[r1:r2]\n",
    "    with torch.no_grad():\n",
    "        pred = model.gap(inputs).cpu().numpy()\n",
    "        input_X[r1:r2] = pred\n",
    "augmentation_data = input_X    # (50000,2048)\n",
    "\n",
    "adv_data.shape,augmentation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"augmentation_data.npy\", augmentation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_data = np.load(\"augmentation_data.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### border_data\n",
    "here we define the border of resnet50 as the logits difference of top1 and top2 is less than 1.5\n",
    "$$logit_{top1}-logit_{top2}<1.5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 Test dataset and dataloader declaration\n",
    "CIFAR_NORM = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(*CIFAR_NORM)])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"attack with epsilon {}...\".format(epsilon))\n",
    "\n",
    "border_data = np.zeros((50000, 3, 32, 32))\n",
    "border_pred_labels = np.zeros(50000)\n",
    "r=0\n",
    "for i, (data, target) in enumerate(trainloader, 0):\n",
    "    \n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Set requires_grad attribute of tensor. Important for Attack\n",
    "    data.requires_grad = True\n",
    "    j=1\n",
    "    while True:\n",
    "        output = model(data)\n",
    "        if j ==1:\n",
    "            print(output.detach().cpu().numpy())\n",
    "        loss = criterion(output, target)  # loss for ground-truth class\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        perturbed_data = adv_attack(data, epsilon, data_grad)\n",
    "\n",
    "        output = model(perturbed_data)\n",
    "        sort, _ = torch.sort(output, dim=-1, descending=True)\n",
    "        abs_dis = sort[0,0]-sort[0,1]\n",
    "        print(abs_dis)\n",
    "#         probabilities = softmax(output).detach().cpu().numpy()\n",
    "#         entropy = -(probabilities*np.log(probabilities)).sum()/np.log(10)\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "        data = torch.from_numpy(np.expand_dims(adv_ex, axis=0)).to(device)\n",
    "        data.requires_grad = True\n",
    "        j = j+1\n",
    "        if final_pred.item() != target:\n",
    "            if abs_dis< 0.5:\n",
    "                border_data[r] = adv_ex\n",
    "                border_pred_labels[r] = final_pred.item()\n",
    "                r = r+1\n",
    "    #             print(i,j,target.detach().cpu().numpy(),\"->\",final_pred.item(),entropy)\n",
    "    #             print(output.detach().cpu().numpy())\n",
    "    #             print(probabilities)\n",
    "            break\n",
    "        if abs_dis < 1.5:\n",
    "            border_data[r] = adv_ex\n",
    "            border_pred_labels[r] = final_pred.item()\n",
    "            r = r+1\n",
    "            break\n",
    "            \n",
    "border_data.shape, border_pred_labels.shape, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_input_X = torch.from_numpy(border_data[:r]).to(device, dtype=torch.float)\n",
    "input_X = np.zeros([len(raw_input_X), data_shape[0]])\n",
    "n_batches = max(math.ceil(len(raw_input_X) / batch_size), 1)\n",
    "for b in range(n_batches):\n",
    "    r1, r2 = b * batch_size, (b + 1) * batch_size\n",
    "    inputs = raw_input_X[r1:r2]\n",
    "    with torch.no_grad():\n",
    "        pred = model.gap(inputs).cpu().numpy()\n",
    "        input_X[r1:r2] = pred\n",
    "border_gap_data = input_X    # (50000,2048)\n",
    "\n",
    "border_gap_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pred_labels = border_pred_labels[:r]\n",
    "border_gap_data.shape, border_pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ifgsm_augmentation_data.npy\", border_gap_data)\n",
    "np.save(\"adv_pred_labels.npy\", border_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18072, 2048), (18072,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_gap_data = np.load(\"ifgsm_augmentation_data.npy\")\n",
    "border_pred_labels = np.load(\"adv_pred_labels.npy\")\n",
    "border_gap_data.shape, border_pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4497, 2048), (4497,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BP_bs = np.load(\"BP_bs.npy\")\n",
    "BP_bs_labels = np.load(\"BP_bs_labels.npy\")\n",
    "BP_bs.shape, BP_bs_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find the N=5000 distance border points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5000).fit(border_gap_data)\n",
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get labels\n",
    "raw_input_X = torch.from_numpy(kmeans.cluster_centers_).to(device, dtype=torch.float)\n",
    "output_Y = np.zeros(len(raw_input_X))\n",
    "n_batches = max(math.ceil(len(raw_input_X) / batch_size), 1)\n",
    "for b in range(n_batches):\n",
    "    r1, r2 = b * batch_size, (b + 1) * batch_size\n",
    "    inputs = raw_input_X[r1:r2]\n",
    "    with torch.no_grad():\n",
    "        pred = model.fc(inputs).cpu().numpy().argmax(axis=1)\n",
    "        output_Y[r1:r2] = pred\n",
    "border_center_labels = output_Y\n",
    "border_center_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"border_center.npy\",kmeans.cluster_centers_)\n",
    "np.save(\"border_center_labels.npy\", border_center_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 2048), (5000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_center = np.load(\"border_center.npy\")\n",
    "border_center_labels= np.load(\"border_center_labels.npy\")\n",
    "border_center.shape, border_center_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## border preserving before DBP\n",
    "1. train_data -> encoder_original\n",
    "2. train_data,ifgsm_augmentation_data -> encoder\n",
    "3. train_data, ifgsm_aumentation_data, DBP -> encoder_border\n",
    "4. train_data, ifgsm_augmentation_data, DBP with modified parametric_umap_DBP -> encoder_DBP\n",
    "5. train_data, ifgsm_aumentation_data, DBP negative_sampling_rate=10 -> encoder_border_10\n",
    "6. train_data, DBP, with ratio 1:1:1 -> encoder_DBP_111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\parametric_umap_autoencoder\\encoder_DBP_010\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_location = \"parametric_umap_models\\parametric_umap_autoencoder\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_original\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'border_center' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7a447566bb7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlow_center\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mborder_center\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlow_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'border_center' is not defined"
     ]
    }
   ],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=N) \n",
    "_, low_ind = low_tree.query(low_train, k=N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33.54342</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method      mean   max  min  median\n",
       "0      1  33.54342  75.0  0.0    33.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "border_preserving = pd.DataFrame(columns = ['method','mean', 'max', 'min', 'median'])\n",
    "border_preserving.loc[len(border_preserving)] = [\"1\",border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)]\n",
    "\n",
    "border_preserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235.8039, 414.0, 36.0, 218.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import trustworthiness\n",
    "tp_trustworthiness = trustworthiness(train_data, low_train, n_neighbors=10, metric='euclidean')\n",
    "inter_dbp_trustworthiness = trustworthiness(border_center, low_center, n_neighbors=10, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.783059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      1         0.783059"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_dbp_knn = pd.DataFrame(columns = ['method','trustworthiness'])\n",
    "inter_dbp_knn.loc[len(inter_dbp_knn)] = ['1', inter_dbp_trustworthiness]\n",
    "inter_dbp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.984133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      1         0.984133"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_knn = pd.DataFrame(columns = ['method','trustworthiness'])\n",
    "tp_knn.loc[len(tp_knn)] = ['1', tp_trustworthiness]\n",
    "\n",
    "tp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\parametric_umap_autoencoder\\encoder\n"
     ]
    }
   ],
   "source": [
    "# loader encoder and decoder\n",
    "# import os\n",
    "save_location = \"parametric_umap_models\\parametric_umap_autoencoder\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))\n",
    "\n",
    "# # load decoder\n",
    "# decoder_output = os.path.join(save_location, \"decoder_border\")\n",
    "# if os.path.exists(decoder_output):\n",
    "#     load_decoder = tf.keras.models.load_model(decoder_output)\n",
    "#     print(\"Keras decoder model loaded from {}\".format(decoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "# from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=N) \n",
    "_, low_ind = low_tree.query(low_train, k=N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180.48812, 412.0, 9.0, 184.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_trustworthiness = trustworthiness(train_data, low_train, n_neighbors=10, metric='euclidean')\n",
    "inter_dbp_trustworthiness = trustworthiness(border_center, low_center, n_neighbors=10, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33.54342</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18.86584</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method      mean   max  min  median\n",
       "0      1  33.54342  75.0  0.0    33.0\n",
       "1      2  18.86584  92.0  0.0    17.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_preserving.loc[len(border_preserving)] = [\"2\",border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)]\n",
    "\n",
    "border_preserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.984133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.983562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      1         0.984133\n",
       "1      2         0.983562"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_knn.loc[len(tp_knn)] = ['2', tp_trustworthiness]\n",
    "\n",
    "tp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.783059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.830742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      1         0.783059\n",
       "1      2         0.830742"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_dbp_knn.loc[len(inter_dbp_knn)] = ['2', inter_dbp_trustworthiness]\n",
    "\n",
    "inter_dbp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\parametric_umap_autoencoder\\encoder_border\n"
     ]
    }
   ],
   "source": [
    "# loader encoder and decoder\n",
    "# import os\n",
    "save_location = \"parametric_umap_models\\parametric_umap_autoencoder\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_border\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))\n",
    "\n",
    "# # load decoder\n",
    "# decoder_output = os.path.join(save_location, \"decoder_DBP\")\n",
    "# if os.path.exists(decoder_output):\n",
    "#     load_decoder = tf.keras.models.load_model(decoder_output)\n",
    "#     print(\"Keras decoder model loaded from {}\".format(decoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "# from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=N) \n",
    "_, low_ind = low_tree.query(low_train, k=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177.40916, 449.0, 0.0, 175.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_trustworthiness = trustworthiness(train_data, low_train, n_neighbors=10, metric='euclidean')\n",
    "inter_dbp_trustworthiness = trustworthiness(border_center, low_center, n_neighbors=10, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33.54342</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18.86584</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18.31906</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method      mean   max  min  median\n",
       "0      1  33.54342  75.0  0.0    33.0\n",
       "1      2  18.86584  92.0  0.0    17.0\n",
       "2      3  18.31906  93.0  0.0    11.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_preserving.loc[len(border_preserving)] = [\"3\",border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)]\n",
    "\n",
    "border_preserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.984133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.983562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.983780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      1         0.984133\n",
       "1      2         0.983562\n",
       "2      3         0.983780"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_knn.loc[len(tp_knn)] = ['3', tp_trustworthiness]\n",
    "\n",
    "tp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.783059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.830742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.853619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      1         0.783059\n",
       "1      2         0.830742\n",
       "2      3         0.853619"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_dbp_knn.loc[len(inter_dbp_knn)] = ['3', inter_dbp_trustworthiness]\n",
    "\n",
    "inter_dbp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\parametric_umap_autoencoder\\encoder_DBP\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "save_location = \"parametric_umap_models\\parametric_umap_autoencoder\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_DBP\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))\n",
    "\n",
    "# # load decoder\n",
    "# decoder_output = os.path.join(save_location, \"decoder_DBP\")\n",
    "# if os.path.exists(decoder_output):\n",
    "#     load_decoder = tf.keras.models.load_model(decoder_output)\n",
    "#     print(\"Keras decoder model loaded from {}\".format(decoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "# from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=N) \n",
    "_, low_ind = low_tree.query(low_train, k=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221.1106, 444.0, 21.0, 198.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_trustworthiness = trustworthiness(train_data, low_train, n_neighbors=10, metric='euclidean')\n",
    "inter_dbp_trustworthiness = trustworthiness(border_center, low_center, n_neighbors=10, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.984133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.983562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.983780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.982697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      1         0.984133\n",
       "1      2         0.983562\n",
       "2      3         0.983780\n",
       "3      4         0.982697"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_knn.loc[len(tp_knn)] = ['4', tp_trustworthiness]\n",
    "\n",
    "tp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.783059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.830742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.853619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.828469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      1         0.783059\n",
       "1      2         0.830742\n",
       "2      3         0.853619\n",
       "3      4         0.828469"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_dbp_knn.loc[len(inter_dbp_knn)] = ['4', inter_dbp_trustworthiness]\n",
    "\n",
    "inter_dbp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33.54342</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18.86584</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18.31906</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>26.02318</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method      mean   max  min  median\n",
       "0      1  33.54342  75.0  0.0    33.0\n",
       "1      2  18.86584  92.0  0.0    17.0\n",
       "2      3  18.31906  93.0  0.0    11.0\n",
       "3      4  26.02318  83.0  0.0    16.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_preserving.loc[len(border_preserving)] = [\"4\",border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)]\n",
    "border_preserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\parametric_umap_autoencoder\\encoder_border_10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_location = \"parametric_umap_models\\parametric_umap_autoencoder\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_border_10\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))\n",
    "\n",
    "# # load decoder\n",
    "# decoder_output = os.path.join(save_location, \"decoder_DBP\")\n",
    "# if os.path.exists(decoder_output):\n",
    "#     load_decoder = tf.keras.models.load_model(decoder_output)\n",
    "#     print(\"Keras decoder model loaded from {}\".format(decoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=100) \n",
    "_, low_ind = low_tree.query(low_train, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.79106, 97.0, 0.0, 13.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import trustworthiness\n",
    "tp_trustworthiness = trustworthiness(train_data, low_train, n_neighbors=10, metric='euclidean')\n",
    "inter_dbp_trustworthiness = trustworthiness(border_center, low_center, n_neighbors=10, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>14.79106</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method      mean   max  min  median\n",
       "0      5  14.79106  97.0  0.0    13.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_preserving = pd.DataFrame(columns = ['method','mean', 'max', 'min', 'median'])\n",
    "border_preserving.loc[len(border_preserving)] = [\"5\",border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)]\n",
    "\n",
    "border_preserving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.983048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      5         0.983048"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_knn = pd.DataFrame(columns = ['method','trustworthiness'])\n",
    "tp_knn.loc[len(tp_knn)] = ['5', tp_trustworthiness]\n",
    "\n",
    "tp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.840593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      5         0.840593"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_dbp_knn = pd.DataFrame(columns = ['method','trustworthiness'])\n",
    "inter_dbp_knn.loc[len(inter_dbp_knn)] = ['5', inter_dbp_trustworthiness]\n",
    "\n",
    "inter_dbp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_trustworthiness = trustworthiness(train_data, low_train, n_neighbors=30, metric='euclidean')\n",
    "inter_dbp_trustworthiness = trustworthiness(border_center, low_center, n_neighbors=30, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_knn.loc[len(tp_knn)] = ['5_30', tp_trustworthiness]\n",
    "inter_dbp_knn.loc[len(inter_dbp_knn)] = ['5_30', inter_dbp_trustworthiness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_trustworthiness = trustworthiness(train_data, low_train, n_neighbors=50, metric='euclidean')\n",
    "inter_dbp_trustworthiness = trustworthiness(border_center, low_center, n_neighbors=50, metric='euclidean')\n",
    "tp_knn.loc[len(tp_knn)] = ['5_50', tp_trustworthiness]\n",
    "inter_dbp_knn.loc[len(inter_dbp_knn)] = ['5_50', inter_dbp_trustworthiness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_trustworthiness = trustworthiness(train_data, low_train, n_neighbors=100, metric='euclidean')\n",
    "inter_dbp_trustworthiness = trustworthiness(border_center, low_center, n_neighbors=100, metric='euclidean')\n",
    "tp_knn.loc[len(tp_knn)] = ['5_100', tp_trustworthiness]\n",
    "inter_dbp_knn.loc[len(inter_dbp_knn)] = ['5_100', inter_dbp_trustworthiness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.983048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5_30</td>\n",
       "      <td>0.982877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5_50</td>\n",
       "      <td>1.017189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5_100</td>\n",
       "      <td>0.999946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      5         0.983048\n",
       "1   5_30         0.982877\n",
       "2   5_50         1.017189\n",
       "3  5_100         0.999946"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.840593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5_30</td>\n",
       "      <td>0.838659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5_50</td>\n",
       "      <td>0.835383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5_100</td>\n",
       "      <td>0.828794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  trustworthiness\n",
       "0      5         0.840593\n",
       "1   5_30         0.838659\n",
       "2   5_50         0.835383\n",
       "3  5_100         0.828794"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_dbp_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\parametric_umap_autoencoder\\encoder_DBP_111\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_location = \"parametric_umap_models\\parametric_umap_autoencoder\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_DBP_111\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-7a447566bb7c>:1: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n"
     ]
    }
   ],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=100) \n",
    "_, low_ind = low_tree.query(low_train, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import trustworthiness\n",
    "tp_trustworthiness = trustworthiness(train_data, low_train, n_neighbors=10, metric='euclidean')\n",
    "inter_dbp_trustworthiness = trustworthiness(border_center, low_center, n_neighbors=10, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9805236570536866, 0.8362489798374962)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_trustworthiness, inter_dbp_trustworthiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.88582, 87.0, 0.0, 19.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=500) \n",
    "_, low_ind = low_tree.query(low_train, k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210.44836, 401.0, 14.0, 221.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\parametric_umap_autoencoder\\encoder_DBP_122\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_location = \"parametric_umap_models\\parametric_umap_autoencoder\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_DBP_122\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-7a447566bb7c>:1: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n"
     ]
    }
   ],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=N) \n",
    "_, low_ind = low_tree.query(low_train, k=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213.3516, 399.0, 5.0, 206.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_pres.mean(),border_pres.max(),border_pres.min(),np.median(border_pres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test encoder/decoder\n",
    "| |M_tptp(original)|\tM_tptp(core)|\tM_tpdp(core)|\tM_(new complex)(core)|\n",
    "|---|---|---|---|---|\n",
    "|K=10|training edge set||||\t|\t\n",
    "||testing edge set||||\t\t\n",
    "|K=20|training edge set\t||||\t\t\t\n",
    "||testing edge set||||\t\t\t\t\n",
    "|K=30|training edge set\t||||\t\t\n",
    "||testing edge set||||\t\t\t\t\n",
    "|K=50|training edge set|||||\n",
    "||testing edge set||||\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Keras encoder model loaded from parametric_umap_models\\dbp_exp\\encoder_core_tpdp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_location = \"parametric_umap_models\\dbp_exp\"\n",
    "# load model\n",
    "# load encoder\n",
    "encoder_output = os.path.join(save_location, \"encoder_core_tpdp\")\n",
    "if os.path.exists(encoder_output):\n",
    "    load_encoder = tf.keras.models.load_model(encoder_output)\n",
    "    print(\"Keras encoder model loaded from {}\".format(encoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_center = load_encoder(border_center).cpu().numpy()\n",
    "# low_center = load_encoder(BP_bs).cpu().numpy()\n",
    "low_train = load_encoder(train_data).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nndescent?\n",
    "from sklearn.neighbors import KDTree\n",
    "high_tree = KDTree(border_center) \n",
    "# high_tree = KDTree(BP_bs) \n",
    "low_tree = KDTree(low_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.42742, 8.0, 0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=10) \n",
    "_, low_ind = low_tree.query(low_train, k=10)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp K=10\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.94338, 17.0, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=20) \n",
    "_, low_ind = low_tree.query(low_train, k=20)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp K=20\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.5892, 22.0, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=30) \n",
    "_, low_ind = low_tree.query(low_train, k=30)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp K=30\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.10516, 35.0, 0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=50) \n",
    "_, low_ind = low_tree.query(low_train, k=50)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp K=50\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.44746, 9.0, 0.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=10) \n",
    "_, low_ind = low_tree.query(low_train, k=10)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp core K=10\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.5924, 16.0, 0.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=20) \n",
    "_, low_ind = low_tree.query(low_train, k=20)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp core K=20\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.17968, 22.0, 0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=30) \n",
    "_, low_ind = low_tree.query(low_train, k=30)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp core K=30\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.64786, 37.0, 0.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=50) \n",
    "_, low_ind = low_tree.query(low_train, k=50)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp core K=50\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.39768, 9.0, 0.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=10) \n",
    "_, low_ind = low_tree.query(low_train, k=10)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp core rho=0 K=10\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.6141, 16.0, 0.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=20) \n",
    "_, low_ind = low_tree.query(low_train, k=20)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp core rho=0 K=20\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.24208, 24.0, 0.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=30) \n",
    "_, low_ind = low_tree.query(low_train, k=30)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp core rho=0 K=30\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.2586, 40.0, 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=50) \n",
    "_, low_ind = low_tree.query(low_train, k=50)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp core rho=0 K=50\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.51554, 10.0, 0.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=10) \n",
    "_, low_ind = low_tree.query(low_train, k=10)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tpdbp core K=10\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.45436, 18.0, 0.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=20) \n",
    "_, low_ind = low_tree.query(low_train, k=20)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tpdbp core K=20\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.43646, 28.0, 0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=30) \n",
    "_, low_ind = low_tree.query(low_train, k=30)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tpdbp core K=30\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.22802, 46.0, 0.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=50) \n",
    "_, low_ind = low_tree.query(low_train, k=50)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tpdbp core K=50\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.31982, 9.0, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=10) \n",
    "_, low_ind = low_tree.query(low_train, k=10)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp tpdbp core K=10\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.63902, 16.0, 0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=20) \n",
    "_, low_ind = low_tree.query(low_train, k=20)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp tpdbp core K=20\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.4789, 24.0, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=30) \n",
    "_, low_ind = low_tree.query(low_train, k=30)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp tpdbp core K=30\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.9191, 38.0, 0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=50) \n",
    "_, low_ind = low_tree.query(low_train, k=50)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# tptp tpdbp core K=50\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.17478, 9.0, 0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k=30\n",
    "_, high_ind = high_tree.query(train_data, k=10) \n",
    "_, low_ind = low_tree.query(low_train, k=10)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# new complex core K=10\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.33074, 19.0, 0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=20) \n",
    "_, low_ind = low_tree.query(low_train, k=20)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# new complex core K=20\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.1065, 29.0, 0.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=30) \n",
    "_, low_ind = low_tree.query(low_train, k=30)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# new complex core K=30\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26.6353, 46.0, 0.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, high_ind = high_tree.query(train_data, k=50) \n",
    "_, low_ind = low_tree.query(low_train, k=50)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# new complex core K=10\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8041, 10.0, 0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k=15\n",
    "_, high_ind = high_tree.query(train_data, k=10) \n",
    "_, low_ind = low_tree.query(low_train, k=10)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# new complex core K=10\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.8586, 20.0, 0.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k=15\n",
    "_, high_ind = high_tree.query(train_data, k=20) \n",
    "_, low_ind = low_tree.query(low_train, k=20)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# new complex core K=20\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.90748, 28.0, 0.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k=15\n",
    "_, high_ind = high_tree.query(train_data, k=30) \n",
    "_, low_ind = low_tree.query(low_train, k=30)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# new complex core K=30\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.87476, 46.0, 0.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k=15\n",
    "_, high_ind = high_tree.query(train_data, k=50) \n",
    "_, low_ind = low_tree.query(low_train, k=50)\n",
    "border_pres = np.zeros(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    border_pres[i] = len(np.intersect1d(high_ind[i],low_ind[i]))\n",
    "# new complex core K=50\n",
    "border_pres.mean(), border_pres.max(),border_pres.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python xianglinDR2",
   "language": "python",
   "name": "dr2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
