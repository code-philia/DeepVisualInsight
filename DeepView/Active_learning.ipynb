{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active learning visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__Author__ = \"zhenfeng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Load Model successfully...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from cifar10_models import *\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = resnet50(pretrained=True)\n",
    "model.to(device)\n",
    "print(\"Load Model successfully...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Strategy:\n",
    "    def __init__(self, X, Y, idxs_lb, net, handler, args):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.idxs_lb = idxs_lb\n",
    "        self.net = net\n",
    "        self.handler = handler\n",
    "        self.args = args\n",
    "        self.n_pool = len(Y)\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    def query(self, n):\n",
    "        pass\n",
    "\n",
    "    def update(self, idxs_lb):\n",
    "        self.idxs_lb = idxs_lb\n",
    "\n",
    "    def _train(self, epoch, loader_tr, optimizer):\n",
    "        self.clf.train()\n",
    "        for batch_idx, (x, y, idxs) in enumerate(loader_tr):\n",
    "            x, y = x.to(self.device), y.long().to(self.device)\n",
    "            optimizer.zero_grad()\n",
    "            out = self.clf(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def train(self, num_round, save_dir):\n",
    "        n_epoch = self.args['n_epoch']\n",
    "        self.clf = self.net\n",
    "        self.clf.to(self.device)\n",
    "        optimizer = optim.SGD(self.clf.parameters(), **self.args['optimizer_args'])\n",
    "\n",
    "        idxs_train = np.arange(self.n_pool)[self.idxs_lb]\n",
    "        loader_tr = DataLoader(self.handler(self.X[idxs_train], self.Y[idxs_train], transform=self.args['transform']),\n",
    "                            shuffle=True, **self.args['loader_tr_args'])\n",
    "        \n",
    "        for epoch in range(1, n_epoch+1):\n",
    "            print(\"epoch: \")\n",
    "            print(epoch)\n",
    "            self._train(epoch, loader_tr, optimizer)\n",
    "            \n",
    "        save_location = os.path.join(save_dir, '{:04d}_round.pt'.format(num_round))\n",
    "        torch.save(self.clf, save_location)\n",
    "\n",
    "    def predict(self, X, Y):\n",
    "        loader_te = DataLoader(self.handler(X, Y, transform=self.args['transform']),\n",
    "                            shuffle=False, **self.args['loader_te_args'])\n",
    "\n",
    "        self.clf.eval()\n",
    "        P = torch.zeros(len(Y), dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            for x, y, idxs in loader_te:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                out = self.clf(x)\n",
    "\n",
    "                pred = out.max(1)[1]\n",
    "                P[idxs] = pred.cpu()\n",
    "\n",
    "        return P\n",
    "\n",
    "    def predict_prob(self, X, Y):\n",
    "        loader_te = DataLoader(self.handler(X, Y, transform=self.args['transform']),\n",
    "                            shuffle=False, **self.args['loader_te_args'])\n",
    "\n",
    "        self.clf.eval()\n",
    "        probs = torch.zeros([len(Y), len(np.unique(Y))])\n",
    "        with torch.no_grad():\n",
    "            for x, y, idxs in loader_te:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                out = self.clf(x)\n",
    "                prob = F.softmax(out, dim=1)\n",
    "                probs[idxs] = prob.cpu()\n",
    "        \n",
    "        return probs\n",
    "\n",
    "    def predict_prob_dropout(self, X, Y, n_drop):\n",
    "        loader_te = DataLoader(self.handler(X, Y, transform=self.args['transform']),\n",
    "                            shuffle=False, **self.args['loader_te_args'])\n",
    "\n",
    "        self.clf.train()\n",
    "        probs = torch.zeros([len(Y), len(np.unique(Y))])\n",
    "        for i in range(n_drop):\n",
    "            print('n_drop {}/{}'.format(i+1, n_drop))\n",
    "            with torch.no_grad():\n",
    "                for x, y, idxs in loader_te:\n",
    "                    x, y = x.to(self.device), y.to(self.device)\n",
    "                    out = self.clf(x)\n",
    "                    prob = F.softmax(out, dim=1)\n",
    "                    probs[idxs] += prob.cpu()\n",
    "        probs /= n_drop\n",
    "        \n",
    "        return probs\n",
    "\n",
    "    def predict_prob_dropout_split(self, X, Y, n_drop):\n",
    "        loader_te = DataLoader(self.handler(X, Y, transform=self.args['transform']),\n",
    "                            shuffle=False, **self.args['loader_te_args'])\n",
    "\n",
    "        self.clf.train()\n",
    "        probs = torch.zeros([n_drop, len(Y), len(np.unique(Y))])\n",
    "        for i in range(n_drop):\n",
    "            print('n_drop {}/{}'.format(i+1, n_drop))\n",
    "            with torch.no_grad():\n",
    "                for x, y, idxs in loader_te:\n",
    "                    x, y = x.to(self.device), y.to(self.device)\n",
    "                    out = self.clf(x)\n",
    "                    probs[i][idxs] += F.softmax(out, dim=1).cpu()\n",
    "        \n",
    "        return probs\n",
    "\n",
    "    def get_embedding(self, X, Y):\n",
    "        loader_te = DataLoader(self.handler(X, Y, transform=self.args['transform']),\n",
    "                            shuffle=False, **self.args['loader_te_args'])\n",
    "\n",
    "        self.clf.eval()\n",
    "        embedding = torch.zeros([len(Y), self.clf.get_embedding_dim()])\n",
    "        with torch.no_grad():\n",
    "            for x, y, idxs in loader_te:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                out, e1 = self.clf(x)\n",
    "                embedding[idxs] = e1.cpu()\n",
    "        \n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RandomSampling(Strategy):\n",
    "    def __init__(self, X, Y, idxs_lb, net, handler, args):\n",
    "        super(RandomSampling, self).__init__(X, Y, idxs_lb, net, handler, args)\n",
    "\n",
    "    def query(self, n):\n",
    "        return np.random.choice(np.where(self.idxs_lb==0)[0], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "def get_dataset(name):\n",
    "    if name == 'MNIST':\n",
    "        return get_MNIST()\n",
    "    elif name == 'FashionMNIST':\n",
    "        return get_FashionMNIST()\n",
    "    elif name == 'SVHN':\n",
    "        return get_SVHN()\n",
    "    elif name == 'CIFAR10':\n",
    "        return get_CIFAR10()\n",
    "\n",
    "def get_MNIST():\n",
    "    raw_tr = datasets.MNIST('./MNIST', train=True, download=True)\n",
    "    raw_te = datasets.MNIST('./MNIST', train=False, download=True)\n",
    "    X_tr = raw_tr.train_data\n",
    "    Y_tr = raw_tr.train_labels\n",
    "    X_te = raw_te.test_data\n",
    "    Y_te = raw_te.test_labels\n",
    "    return X_tr, Y_tr, X_te, Y_te\n",
    "\n",
    "def get_FashionMNIST():\n",
    "    raw_tr = datasets.FashionMNIST('./FashionMNIST', train=True, download=True)\n",
    "    raw_te = datasets.FashionMNIST('./FashionMNIST', train=False, download=True)\n",
    "    X_tr = raw_tr.train_data\n",
    "    Y_tr = raw_tr.train_labels\n",
    "    X_te = raw_te.test_data\n",
    "    Y_te = raw_te.test_labels\n",
    "    return X_tr, Y_tr, X_te, Y_te\n",
    "\n",
    "def get_SVHN():\n",
    "    data_tr = datasets.SVHN('./SVHN', split='train', download=True)\n",
    "    data_te = datasets.SVHN('./SVHN', split='test', download=True)\n",
    "    X_tr = data_tr.data\n",
    "    Y_tr = torch.from_numpy(data_tr.labels)\n",
    "    X_te = data_te.data\n",
    "    Y_te = torch.from_numpy(data_te.labels)\n",
    "    return X_tr, Y_tr, X_te, Y_te\n",
    "\n",
    "def get_CIFAR10():\n",
    "    data_tr = datasets.CIFAR10('./CIFAR10', train=True, download=True)\n",
    "    data_te = datasets.CIFAR10('./CIFAR10', train=False, download=True)\n",
    "    X_tr = data_tr.data\n",
    "    Y_tr = torch.from_numpy(np.array(data_tr.targets))\n",
    "    X_te = data_te.data\n",
    "    Y_te = torch.from_numpy(np.array(data_te.targets))\n",
    "    return X_tr, Y_tr, X_te, Y_te\n",
    "\n",
    "def get_handler(name):\n",
    "    if name == 'MNIST':\n",
    "        return DataHandler1\n",
    "    elif name == 'FashionMNIST':\n",
    "        return DataHandler1\n",
    "    elif name == 'SVHN':\n",
    "        return DataHandler2\n",
    "    elif name == 'CIFAR10':\n",
    "        return DataHandler3\n",
    "\n",
    "class DataHandler1(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.X[index], self.Y[index]\n",
    "        if self.transform is not None:\n",
    "            x = Image.fromarray(x.numpy(), mode='L')\n",
    "            x = self.transform(x)\n",
    "        return x, y, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "class DataHandler2(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.X[index], self.Y[index]\n",
    "        if self.transform is not None:\n",
    "            x = Image.fromarray(np.transpose(x, (1, 2, 0)))\n",
    "            x = self.transform(x)\n",
    "        return x, y, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "class DataHandler3(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.X[index], self.Y[index]\n",
    "        if self.transform is not None:\n",
    "            x = Image.fromarray(x)\n",
    "            x = self.transform(x)\n",
    "        return x, y, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "number of labeled pool: 10000\n",
      "number of unlabeled pool: 30000\n",
      "number of testing pool: 10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# parameters\n",
    "SEED = 1\n",
    "\n",
    "NUM_INIT_LB = 10000\n",
    "NUM_QUERY = 1000\n",
    "NUM_ROUND = 10\n",
    "\n",
    "#DATA_NAME = 'MNIST'\n",
    "# DATA_NAME = 'FashionMNIST'\n",
    "# DATA_NAME = 'SVHN'\n",
    "DATA_NAME = 'CIFAR10'\n",
    "\n",
    "args_pool = {'MNIST':\n",
    "                {'n_epoch': 10, 'transform': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "                 'loader_tr_args':{'batch_size': 64, 'num_workers': 1},\n",
    "                 'loader_te_args':{'batch_size': 1000, 'num_workers': 1},\n",
    "                 'optimizer_args':{'lr': 0.01, 'momentum': 0.5}},\n",
    "            'FashionMNIST':\n",
    "                {'n_epoch': 10, 'transform': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "                 'loader_tr_args':{'batch_size': 64, 'num_workers': 1},\n",
    "                 'loader_te_args':{'batch_size': 1000, 'num_workers': 1},\n",
    "                 'optimizer_args':{'lr': 0.01, 'momentum': 0.5}},\n",
    "            'SVHN':\n",
    "                {'n_epoch': 20, 'transform': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970))]),\n",
    "                 'loader_tr_args':{'batch_size': 64, 'num_workers': 1},\n",
    "                 'loader_te_args':{'batch_size': 1000, 'num_workers': 1},\n",
    "                 'optimizer_args':{'lr': 0.01, 'momentum': 0.5}},\n",
    "            'CIFAR10':\n",
    "                {'n_epoch': 5, 'transform': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))]),\n",
    "                 'loader_tr_args':{'batch_size': 64, 'num_workers': 0},\n",
    "                 'loader_te_args':{'batch_size': 1000, 'num_workers': 0},\n",
    "                 'optimizer_args':{'lr': 0.05, 'momentum': 0.3}} #num of n_epoch is recommended to be 20, here lower to 5 to speed up\n",
    "            }\n",
    "args = args_pool[DATA_NAME]\n",
    "\n",
    "# set seed\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "# load dataset\n",
    "X_tr, Y_tr, X_te, Y_te = get_dataset(DATA_NAME)\n",
    "X_tr = X_tr[:40000]\n",
    "Y_tr = Y_tr[:40000]\n",
    "\n",
    "# start experiment\n",
    "n_pool = len(Y_tr)\n",
    "n_test = len(Y_te)\n",
    "print('number of labeled pool: {}'.format(NUM_INIT_LB))\n",
    "print('number of unlabeled pool: {}'.format(n_pool - NUM_INIT_LB))\n",
    "print('number of testing pool: {}'.format(n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10\n",
      "SEED 1\n",
      "RandomSampling\n"
     ]
    }
   ],
   "source": [
    "# generate initial labeled pool\n",
    "idxs_lb = np.zeros(n_pool, dtype=bool)\n",
    "idxs_tmp = np.arange(n_pool)\n",
    "np.random.shuffle(idxs_tmp)\n",
    "idxs_lb[idxs_tmp[:NUM_INIT_LB]] = True\n",
    "\n",
    "# load network\n",
    "#net = get_net(DATA_NAME)\n",
    "net = model\n",
    "handler = get_handler(DATA_NAME)\n",
    "\n",
    "strategy = RandomSampling(X_tr, Y_tr, idxs_lb, net, handler, args)\n",
    "# strategy = LeastConfidence(X_tr, Y_tr, idxs_lb, net, handler, args)\n",
    "# strategy = MarginSampling(X_tr, Y_tr, idxs_lb, net, handler, args)\n",
    "# strategy = EntropySampling(X_tr, Y_tr, idxs_lb, net, handler, args)\n",
    "# strategy = LeastConfidenceDropout(X_tr, Y_tr, idxs_lb, net, handler, args, n_drop=10)\n",
    "# strategy = MarginSamplingDropout(X_tr, Y_tr, idxs_lb, net, handler, args, n_drop=10)\n",
    "# strategy = EntropySamplingDropout(X_tr, Y_tr, idxs_lb, net, handler, args, n_drop=10)\n",
    "# strategy = KMeansSampling(X_tr, Y_tr, idxs_lb, net, handler, args)\n",
    "# strategy = KCenterGreedy(X_tr, Y_tr, idxs_lb, net, handler, args)\n",
    "# strategy = BALDDropout(X_tr, Y_tr, idxs_lb, net, handler, args, n_drop=10)\n",
    "# strategy = CoreSet(X_tr, Y_tr, idxs_lb, net, handler, args)\n",
    "# strategy = AdversarialBIM(X_tr, Y_tr, idxs_lb, net, handler, args, eps=0.05)\n",
    "# strategy = AdversarialDeepFool(X_tr, Y_tr, idxs_lb, net, handler, args, max_iter=50)\n",
    "# albl_list = [MarginSampling(X_tr, Y_tr, idxs_lb, net, handler, args),\n",
    "#              KMeansSampling(X_tr, Y_tr, idxs_lb, net, handler, args)]\n",
    "# strategy = ActiveLearningByLearning(X_tr, Y_tr, idxs_lb, net, handler, args, strategy_list=albl_list, delta=0.1)\n",
    "\n",
    "# print info\n",
    "print(DATA_NAME)\n",
    "print('SEED {}'.format(SEED))\n",
    "print(type(strategy).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "Round 0\n",
      "testing accuracy 0.3631\n",
      "Round 1\n",
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "testing accuracy 0.5876\n",
      "Round 2\n",
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "testing accuracy 0.5656\n",
      "Round 3\n",
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "testing accuracy 0.6534\n",
      "Round 4\n",
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "testing accuracy 0.6775\n",
      "Round 5\n",
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "testing accuracy 0.5649\n",
      "Round 6\n",
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "testing accuracy 0.6987\n",
      "Round 7\n",
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "testing accuracy 0.7318\n",
      "Round 8\n",
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "testing accuracy 0.674\n",
      "Round 9\n",
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "testing accuracy 0.7422\n",
      "Round 10\n",
      "epoch: \n",
      "1\n",
      "epoch: \n",
      "2\n",
      "epoch: \n",
      "3\n",
      "epoch: \n",
      "4\n",
      "epoch: \n",
      "5\n",
      "testing accuracy 0.748\n",
      "SEED 1\n",
      "RandomSampling\n",
      "[0.3631 0.5876 0.5656 0.6534 0.6775 0.5649 0.6987 0.7318 0.674  0.7422\n",
      " 0.748 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = \"ActiveLearningModels\"\n",
    "idxs_lb_0_location = os.path.join(save_dir,'idxs_lb_'+str(0)+'.json')\n",
    "\n",
    "with open(idxs_lb_0_location, 'w') as f:\n",
    "    json.dump(idxs_lb.tolist(), f)\n",
    "# round 0 accuracy\n",
    "strategy.train(0, save_dir)\n",
    "P = strategy.predict(X_te, Y_te)\n",
    "acc = np.zeros(NUM_ROUND+1)\n",
    "acc[0] = 1.0 * (Y_te==P).sum().item() / len(Y_te)\n",
    "print('Round 0\\ntesting accuracy {}'.format(acc[0]))\n",
    "\n",
    "for rd in range(1, NUM_ROUND+1):\n",
    "    \n",
    "    print('Round {}'.format(rd))\n",
    "\n",
    "    # query\n",
    "    q_idxs = strategy.query(NUM_QUERY)\n",
    "    idxs_lb[q_idxs] = True\n",
    "    \n",
    "    idxs_lb_location = os.path.join(save_dir,'idxs_lb_'+str(rd)+'.json')\n",
    "    with open(idxs_lb_location, 'w') as f:\n",
    "      json.dump(idxs_lb.tolist(), f)\n",
    "\n",
    "    # update\n",
    "    strategy.update(idxs_lb)\n",
    "    strategy.train(rd, save_dir)\n",
    "\n",
    "    # round accuracy\n",
    "    P = strategy.predict(X_te, Y_te)\n",
    "    acc[rd] = 1.0 * (Y_te==P).sum().item() / len(Y_te)\n",
    "    print('testing accuracy {}'.format(acc[rd]))\n",
    "\n",
    "# print results\n",
    "print('SEED {}'.format(SEED))\n",
    "print(type(strategy).__name__)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python xianglinDR2",
   "language": "python",
   "name": "dr2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
